


+ 程序在本机测试正常，放到网络上运行就经常出现数据收不全的情况？
+ TCP 协议真的有所谓的“[[粘包]]问题”吗？该如何设计消息帧的协议？又该如何编码实现分包才不会掉到陷阱里？
+ 带外数据（OOB）、信号驱动 IO 这些高级特性到底有没有用？
+ 网络协议格式该怎么设计？发送 C struct 会有对齐方面的问题吗？对方不用 C/C++怎么通信？将来服务端软件升级，需要在协议中增加一个字段，现有的客户端就必须强制升级？
+ 要处理成千上万的并发连接，似乎《UNIX 网络编程》介绍的传统 fork () 模型应付不过来，该用哪种并发模型呢？试试 select (2)/poll (2)/epoll (4) 这种 IO 复用模型吧，又感觉非阻塞 IO 陷阱重重，怎么程序的 CPU 使用率一直是 100%？
+ 要不改用现成的 libevent 网络库吧，怎么查询一下数据库就把其他连接上的请求给耽误了？再用个线程池吧。万一发回响应的时候对方已经断开连接了怎么办？会不会串话？
+ 读过《UNIX 环境高级编程》，想用多线程来发挥多核 CPU 的性能潜力，但对程序该用哪种多线程模型感到一头雾水？有没有值得推荐的适用面广的多线程 IO 模型？互斥器、条件变量、读写锁、信号量这些底层同步原语哪些该用哪些不该用？有没有更高级的同步设施能简化开发？《UNIX 网络编程（第 2 卷）》介绍的那些琳琅满目的进程间通信（IPC）机制到底用哪个才能兼顾开发效率与可伸缩性？
+ 网络编程和多线程编程的基础打得差不多，开始实际做项目了，更多问题扑面而来：
+ 网上听人说服务端开发要做到 7×24 运行，为了防止内存碎片连动态内存分配都不能用，那岂不是连 C++ STL 也一并禁用了？硬件的可靠性高到值得去这么做吗？
+ 传闻服务端开发主要通过日志来查错，那么日志里该写些什么？日志是写给谁看的？怎样写日志才不会影响性能？
+ 分布式系统跟单机多进程到底有什么本质区别？心跳协议为什么是必需的，该如何实现？
+ C++的大型工程该如何管理？库的接口如何设计才能保证升级的时候不破坏二进制兼容性？有没有更适合大规模分布式系统的部署方案