---
doc_type: weread-highlights-reviews
bookId: "3300054430"
author: 苏达哈尔桑·拉维昌迪兰
cover: https://cdn.weread.qq.com/weread/cover/67/cpplatform_9qo7wsboy6dnxbfsmkgt57/t7_cpplatform_9qo7wsboy6dnxbfsmkgt571680520804.jpg
reviewCount: 0
noteCount: 3
readingStatus: 在读
progress: 71%
totalReadDay: 2
readingTime: 0小时35分钟
readingDate: 2023-05-28
isbn: 9787115603722
lastReadDate: 2023-08-21

---
# 元数据
> [!abstract] BERT基础教程：Transformer大模型实战
> - ![ BERT基础教程：Transformer大模型实战|200](https://cdn.weread.qq.com/weread/cover/67/cpplatform_9qo7wsboy6dnxbfsmkgt57/t7_cpplatform_9qo7wsboy6dnxbfsmkgt571680520804.jpg)
> - 书名： BERT基础教程：Transformer大模型实战
> - 作者： 苏达哈尔桑·拉维昌迪兰
> - 简介： 本书聚焦谷歌公司开发的BERT自然语言处理模型，由浅入深地介绍了BERT的工作原理、BERT的各种变体及其应用。本书呈现了大量示意图、代码和实例，详细解析了如何训练BERT模型、如何使用BERT模型执行自然语言推理任务、文本摘要任务、问答任务、命名实体识别任务等各种下游任务，以及如何将BERT模型应用于多种语言。通读本书后，读者不仅能够系统了解有关BERT的各种概念、术语和原理，还能够使用BERT模型及其变体执行各种自然语言处理任务。
> - 出版时间 2023-02-01 00:00:00
> - ISBN： 9787115603722
> - 分类： 计算机-软件学习
> - 出版社： 人民邮电出版社有限公司
> - PC地址：https://weread.qq.com/web/reader/96132c70813ab7bc3g01028a

# 高亮划线

### 第3章 BERT实战

> 📌 下面，我们将学习如何使用预训练的BERT模型作为特征提取器来提取嵌入，然后详细学习如何为下游任务微调预训练的BERT模型。 
> ⏱ 2023-08-21 08:27:39 ^3300054430-8-2337-2398

> 📌 要让模型理解[PAD]标记只是为了匹配标记的长度，而不是实际标记的一部分。为了做到这一点，我们需要引入一个注意力掩码。我们将所有位置的注意力掩码值设置为1，将[PAD]标记的位置设置为0 
> ⏱ 2023-08-21 08:30:09 ^3300054430-8-4081-4174

> 📌 请注意，使用[CLS]标记的特征代表整个句子的特征并不总是一个好主意。要获得一个句子的特征，最好基于所有标记的特征进行平均或者汇聚。 
> ⏱ 2023-08-21 09:58:02 ^3300054430-8-6174-6240

# 读书笔记

# 本书评论
