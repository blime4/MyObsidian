Abstract
1. 以往方法的不足：
	1. Existing solutions such as data and model parallelisms exhibit fundamental limitations to fit these models into limited device memory, while obtaining computation, communication and development efficiency.
		1. 现有的解决方案（如数据和模型并行性）在将这些模型放入有限的设备内存中，同时获得计算、通信和开发效率方面存在根本性局限性。
2. Zero 的成果：
	1. This represents an 8x increase in model size and 10x increase in achievable performance over state-of-the-art.
		1. 这意味着与最先进的设备相比，模型尺寸增加了 8 倍，可实现的性能提高了 10 倍。
	2. researchers have used the system breakthroughs of ZeRO to create the world’s largest language model (17B parameters) with record breaking accuracy.
		1. 研究人员利用 ZeRO 的系统突破，以破纪录的精度创建了世界上最大的语言模型（17B 参数）。
3. 