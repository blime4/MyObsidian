决策树学习基本算法:
![[Pasted image 20240312104052.png]]

## 1. 划分选择
我们希望决策树的分支结点所包含的样本尽可能属于同一类别，即结点的“纯度” (purity) 越来越高.
1. [[信息增益]]
	1. [[信息熵]]
	2. 决策树生成步骤：
		1. 计算出根节点的信息熵
		2. 计算出其他属性的信息增益
			1. 如：![[Pasted image 20240312190024.png]]
			2. 纹理的信息增益最大
		3. 找出信息增益最大的，进行划分
		4. 重复 2-3
		5. 得到最终的决策树：
			1. 如：![[Pasted image 20240312190152.png]]
		6. 
	3. 缺点：
		1. 信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来的不利影响
		2. 改进：使用 [[增益率]]
2. [[增益率]]
3. [[基尼指数]]
## 2. 剪枝处理
## 3. 连续与缺失值
## 4. 多变量与决策树
## 5. 参考资料

