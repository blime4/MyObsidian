---
doc_type: weread-highlights-reviews
bookId: "36985175"
author: 张臣雄
cover: https://wfqqreader-1252317822.image.myqcloud.com/cover/175/36985175/t7_36985175.jpg
reviewCount: 3
noteCount: 14
readingStatus: 读过
progress: 35%
totalReadDay: 8
readingTime: 3小时33分钟
readingDate: 2022-08-30
isbn: 9787115553195
lastReadDate: 2022-09-05

---
# 元数据
> [!abstract] AI芯片：前沿技术与创新未来
> - ![ AI芯片：前沿技术与创新未来|200](https://wfqqreader-1252317822.image.myqcloud.com/cover/175/36985175/t7_36985175.jpg)
> - 书名： AI芯片：前沿技术与创新未来
> - 作者： 张臣雄
> - 简介： 本书从AI的发展历史讲起，介绍了目前最热门的深度学习加速芯片和基于神经形态计算的类脑芯片的相关算法、架构、电路等，并介绍了近年来产业界和学术界一些著名的AI芯片，包括生成对抗网络芯片和深度强化学习芯片等。本书着重介绍了用创新的思维来设计AI芯片的各种计算范式，以及下一代AI芯片的几种范例，包括量子启发的AI芯片、进一步提升智能程度的AI芯片、有机自进化AI芯片、光子AI芯片及自供电AI芯片等。本书也介绍了半导体芯片技术在“后摩尔定律时代”的发展趋势，以及基础理论（如量子场论、信息论等）引领AI芯片创新并将不断发挥巨大作用。最后，本书介绍了AI发展的三个层次、AI芯片与生物大脑的差距以及未来的发展方向。本书可供在AI芯片领域学习和工作的研究生、本科生、工程技术人员，以及所有对AI芯片感兴趣的人员参考。
> - 出版时间 2021-03-01 00:00:00
> - ISBN： 9787115553195
> - 分类： 计算机-人工智能
> - 出版社： 人民邮电出版社
> - PC地址：https://weread.qq.com/web/reader/9f132cf0723459579f1dd43

# 高亮划线

## 第一篇 导论

> 📌 这种“自学习”的性能，很可能随时间呈指数级提升，并将最终导致智能机器的智能水平超越人类。 
> ⏱ 2022-08-31 09:41:43 ^36985175-6-13967-14011

> 📌 但截至目前，单处理器计算仍占上风。然而，通用计算正在向并行架构迈出不可逆转的步伐，因为单线程单处理器的性能无法再以过去那种速度提高。 
> ⏱ 2022-08-31 09:43:56 ^36985175-6-14565-14631

> 📌 真实世界的应用是并行的，硬件也可以做到并行，而缺少的是编程模型和支持这些不断发展的大规模并行计算体系结构的系统软件。此外，如何在多核架构的计算能力、存储器容量及内部和外部通信带宽之间取得平衡，目前尚无明确共识。 
> ⏱ 2022-08-31 09:45:03 ^36985175-6-14683-14788

> 📌 具有专用于张量处理功能的结构 
> ⏱ 2022-08-31 09:50:16 ^36985175-6-15155-15169

> 📌 这种芯片基于新的芯片架构，关键组成部分包含脉冲神经元、低精度突触和可扩展的通信网络等。 
> ⏱ 2022-08-31 10:20:58 ^36985175-6-15774-15817

### 第2章 执行“训练”和“推理”的AI 芯片

> 📌 这些改进有的是在算法上作些改动，如剪枝、压缩、二值或多值逻辑、稀疏网络等；有的是网络架构上的改动，如图神经网络（Graph Neural Network，GNN[3]，不进行张量运算而改用图形的节点和边来计算）、胶囊网络（Capsule Network）[4]、深度森林（Deep Forest[5]，基于决策树方法，超参数少，显示出无须反向传播即可构建深度模型的可能性 
> ⏱ 2022-09-01 08:48:02 ^36985175-7-3805-4023

> 📌 无监督学习的一个主要挑战是如何定义两个特征或输入数据之间的相似性；另一个挑战是不同的算法可能导致不同的结果，这需要专家再来分析它们。 
> ⏱ 2022-09-01 19:08:40 ^36985175-7-5412-5478

> 📌 整体同步并行计算 
> ⏱ 2022-09-04 21:20:33 ^36985175-7-15413-15421

## 第二篇 最热门的AI芯片

> 📌 二值网络、三值网络 
> ⏱ 2022-09-04 22:34:48 ^36985175-8-3995-4004

> 📌 因此，有研究人员想到了使用在20世纪80年代比较热门的脉动式阵列，将复杂的脉动数据流精心组织到MAC处理单元之中[7,10]。在AI芯片中，脉动式阵列方法于2015年首次应用于谷歌的TPU中，目前已经广泛应用于基于深度学习的AI芯片中。在这种架构中，计算结果从一个MAC直接传输到另一个MAC，没有寄存器的读写过程，并自动计算乘积累加。这样，每个MAC的功耗可以降低至原来的1/10～1/5。而且这种架构很容易扩展，谷歌就使用了一个256×256的阵列，覆盖了65,536个MAC。 
> ⏱ 2022-09-05 13:25:12 ^36985175-8-7255-7507

> 📌 对存内计算来说，存储器本身就可以进行计算（存算一体化），存储架构要简单得多，从而可大大降低时延和功耗 
> ⏱ 2022-09-05 13:29:02 ^36985175-8-9699-9749

> 📌 高通研究人员介绍了一种量化方法[16]，称为无数据量化（Data-Free Quantization，DFQ）技术。这种量化技术不需要数据、微调或超参数调整，从而改进了量化性能，提高了系统精度，在将fp32模型量化为int8时仍能实现接近原始的模型性能。 
> ⏱ 2022-09-05 13:40:38 ^36985175-8-13614-13752

> 📌 比利时研究人员还提出了最小能量量化神经网络（Quantized Neural Network，QNN）[21]，通过量化训练提供对任意数量的位宽和任何网络拓扑的网络量化的明确控制，并将其链接到推理能量模型。这可以既优化所使用的算法，也优化硬件架构，适用于“永远在线”“永远开启”的嵌入式AI应用。 
> ⏱ 2022-09-05 13:41:16 ^36985175-8-13815-13974

> 📌 最后得出结论，能耗取决于所需的精度、计算精度和可用的片上存储器。int4实现通常被认为是最小能量解决方案。 
> ⏱ 2022-09-05 13:43:11 ^36985175-8-14100-14153

# 读书笔记

## 第一篇 导论

### 划线评论
> 📌 ；2018年之后，每天约有100篇关于这方面新的算法和思路的技术论文发表  ^10284435-7BUScGCX6
    - 💭 🐮
    - ⏱ 2022-08-31 09:55:51
   
## 第二篇 最热门的AI芯片

### 划线评论
> 📌 也有些研究人员提出使用“多种精度混合”的自适应方法，根据不同的需求对位宽进行灵活变换，这样既满足了减少计算量的要求，也能保持训练精度不变  ^10284435-7C2I5Gqm6
    - 💭 mixed precision

    - ⏱ 2022-09-05 13:34:48

### 划线评论
> 📌 谷歌发明的16位脑浮点（Brain Floating Point，bf16或bfloat16）格式与fp16相比增加了动态范围，与标准fp32相同。大多数情况下，用户在进行神经网络计算时，bf16格式与fp32一样准确，但是能以一半的位宽完成任务。因此，与fp32相比，采用bf16可以使吞吐量翻倍、内存需求减半。  ^10284435-7C2Ia0iPQ
    - 💭 ！
    - ⏱ 2022-09-05 13:35:52
   
# 本书评论
