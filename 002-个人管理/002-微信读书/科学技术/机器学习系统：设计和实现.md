---
doc_type: weread-highlights-reviews
bookId: "3300060861"
author: 麦络 董豪
cover: https://cdn.weread.qq.com/weread/cover/48/cpplatform_iz6ofcwvftphshnahwkjux/t7_cpplatform_iz6ofcwvftphshnahwkjux1686026058.jpg
reviewCount: 0
noteCount: 5
readingStatus: 在读
progress: 22%
totalReadDay: 1
readingTime: 2小时43分钟
readingDate: 2023-06-09
isbn: 9787302630074
lastReadDate: 2023-06-09

---
# 元数据
> [!abstract] 机器学习系统：设计和实现
> - ![ 机器学习系统：设计和实现|200](https://cdn.weread.qq.com/weread/cover/48/cpplatform_iz6ofcwvftphshnahwkjux/t7_cpplatform_iz6ofcwvftphshnahwkjux1686026058.jpg)
> - 书名： 机器学习系统：设计和实现
> - 作者： 麦络 董豪
> - 简介： 本书系统地介绍了机器学习系统的设计原则和实践经验，侧重于介绍机器学习的原理、神经网络和优化器、自动差分算法、机器学习系统编程模型、控制流和数据流，异构硬件加速器的原理和编程、数据流图编译器前端、数据流图编译器后端、数据准备和增强、模型部署相关技术、分布式训练、弹性训练、联合训练和评估平台、调试和优化工具、数据隐私和安全等。在讲授的过程中，本书将根据MindSpore的自身特点，在各个章节突出讨论MindSpore的优势点，从而将MindSpore并列为与TensorFlow，PyTorch的三大框架。
> - 出版时间 2023-03-01 00:00:00
> - ISBN： 9787302630074
> - 分类： 科学技术-工业技术
> - 出版社： 清华大学出版社
> - PC地址：https://weread.qq.com/web/reader/fcb320f0813ab7e46g0113d2

# 高亮划线

### 第2章 编程模型

> 📌 神经网络的优化器有两类：一类是学习率不受梯度影响的随机梯度下降(Stochastic Gradient Descent,SGD)及SGD的一些改进方法，如带有Momentum的SGD；另一类是自适应学习率，如AdaGrad、RMSProp、Adam等。 
> ⏱ 2023-06-09 12:34:11 ^3300060861-8-8525-8651

> 📌 SGD的更新是对每个样本进行梯度下降，因此计算速度很快，但是单样本更新频繁，会造成震荡；为了解决震荡问题，提出了带有Momentum的SGD，该方法的参数更新不仅仅由梯度决定，也和累计的梯度下降方向有关，使得增加更新梯度下降方向不变的维度，减少更新梯度下降方向改变的维度，从而速度更快，震荡也减少了。 
> ⏱ 2023-06-09 12:34:25 ^3300060861-8-8699-8856

> 📌 dataset_sink_mode用于控制数据是否下沉，数据下沉是指数据通过通道直接传送到设备(Device)上，可以加快训练速度，dataset_sink_mode为真(True)，表示数据下沉，否则为非下沉。 
> ⏱ 2023-06-09 12:36:29 ^3300060861-8-10641-10747

> 📌 需要注意的是，每个通道都有各自的卷积核，同一个通道的卷积核参数共享。如果输出通道为outc，输入通道为inc，那么需要outc×inc个卷积核。 
> ⏱ 2023-06-09 12:40:13 ^3300060861-8-14575-14747

> 📌 现代机器学习框架（包括TensorFlow、PyTorch和MindSpore）主要依赖Pybind11将底层的大量C和C++函数自动生成对应的Python函数，这一过程一般称为Python绑定(Binding)。 
> ⏱ 2023-06-09 12:48:35 ^3300060861-8-21478-21585

# 读书笔记

# 本书评论
