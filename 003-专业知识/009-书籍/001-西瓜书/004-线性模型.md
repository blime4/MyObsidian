1. 线性回归
	1. [[序关系]] （order）
	2. [[均方误差]] 
		1. ---几何意义 ---> [[欧氏距离]] 
		2. ---基于均方误差最小化模型求解的方法叫做---> [[最小二乘法]]
	3. 多元线性回归
		1. 满秩矩阵
		2. 非满秩矩阵
			1. 多组解 
				1. ---如何选择一组解作为输出---> [[归纳偏好]] ---最常见的方法---> [[正则化]]
	4. [[对数线性回归]]
		1. $$ln y = w^T+b$$
			1. 实际上时试图让 $$e^{w^T+b}$$ 逼近  $y$
			2. ---本质是---> 求输入空间到输出空间的非线性函数映射
			3. ---更一般地---> 引出了 "[[广义线性模型]]"
				1. $g(.)$ 是一个单调可微函数
				2. 当 $g(.)$ = $ln(.)$ 是为对数线性回归
					1. $$y = g^{-1}(w^Tx+b)$$
	5. [[对数几率回归]]
		1. ---如何使用线性模型做回归学习---> [[广义线性模型]] 
			1. ---找出一个单调可微函数将分类任务的真实标记 y 与线性回归模型的预测值联系起来
				1. [[单位跳跃函数]] | 不连续
				2. [[对数几率函数]] | 连续 | 单调可微
					1. [[sigmoid函数]]
					2. 优点： #不是很懂 
						1. 直接对回归可能性建模，无需事先假设数据分布
							1. 避免了假设分布不准确导致的问题
						2. 不仅可以预测出“类别“，还可得到近似概率预测
							1. 对许多需要利用概率辅助的决策很有帮助
					3.  ---目标函数---> 是任意阶可导的凸函数
					4. 在此利用 [[最大似然估计]] 估计出 w 和 b #不是很懂 #未看完 
	6. [[线性判别分析]]
		1. Linear Discriminant Analysis | LDA
		2. #未看完 #不是很懂 
	7. [[多分类学习]] #未看完 
	8. [[类别不平衡问题]] #未看完 
	9. 
			
